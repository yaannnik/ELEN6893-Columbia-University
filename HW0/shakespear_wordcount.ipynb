{"cells":[{"cell_type":"code","execution_count":1,"source":["from pyspark import SparkContext\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","stop_words = set(stopwords.words('english'))\n","punkt = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%', '\\'', '\\'s', '\\'d']\n","\n","sc = SparkContext('local','WordCount')"],"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/yangyi/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /Users/yangyi/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["textFile = sc.textFile('./shakes.txt')\n","top = 10\n","\n","wordCount = textFile.collect()\n","\n","# turn words into lowercase\n","words = [word_tokenize(words.lower()) for words in wordCount]\n","words = [word for line in words for word in line]\n","\n","wordCount = sc.parallelize(words)\n","\n","wordCount = wordCount.filter(lambda x: (x != '') and (x not in punkt)) \\\n","    .map(lambda x: (x, 1)) \\\n","    .reduceByKey(lambda a, b: a + b) \\\n","    .sortBy(lambda x: x[1], False).take(top)\n","\n","for key, value in wordCount:\n","    print('%s, %i' % (key, value))"],"outputs":[{"output_type":"stream","name":"stdout","text":["the, 764\n","and, 599\n","to, 460\n","of, 427\n","i, 345\n","a, 285\n","you, 271\n","that, 254\n","is, 248\n","in, 224\n"]}],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["filtered_wordCount = textFile.collect()\n","\n","# turn words into lowercase\n","words = [word_tokenize(words.lower()) for words in filtered_wordCount]\n","words = [word for line in words for word in line]\n","\n","filtered_wordCount = sc.parallelize(words) \\\n","    .filter(lambda x: (x not in stop_words) and (x != '') and (x not in punkt)) \\\n","    .map(lambda x: (x, 1)).reduceByKey(lambda a, b: a + b) \\\n","    .sortBy(lambda x: x[1], False).take(top)\n","\n","for key, value in filtered_wordCount:\n","    print('%s, %d' % (key, value))"],"outputs":[{"output_type":"stream","name":"stdout","text":["macb, 137\n","haue, 122\n","thou, 87\n","enter, 81\n","shall, 68\n","macbeth, 67\n","thee, 61\n","vpon, 60\n","macd, 58\n","vs, 57\n"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"interpreter":{"hash":"a6f43bc8b6817fe41e0368aeedec29e97a64392d98a2288e05ac37c2a985d986"}},"nbformat":4,"nbformat_minor":2}